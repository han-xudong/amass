{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Body Data\n",
    "AMASS uses [MoSh++](https://amass.is.tue.mpg.de) pipeline to fit [SMPL+H body model](https://mano.is.tue.mpg.de/)\n",
    "to marker based human motion capture (mocap) data.\n",
    "[These mocaps](https://amass.is.tue.mpg.de) are from different publicly available datasets.\n",
    "A single data file in amass has the parameters to control gender, pose, shape, global rotation, translation and soft tissue dynamics\n",
    "in correspondence with the original motion capture sequence.\n",
    "Here we present code snippets to render a body image with these parameters.\n",
    "Mocap is a time sequence data, and you can visualize the \"moshed\" per frame results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from os import path as osp\n",
    "\n",
    "support_dir = '../support_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Choose the device to run the body model on.\n",
    "comp_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {comp_device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "We assume you have downloaded the required body model and placed them in body_models directory of this repository.\n",
    "For SMPL+H body model, download it from http://mano.is.tue.mpg.de/.\n",
    "Please download the AMASS version of the model with DMPL blendshapes.\n",
    "You can obtain dynamic shape blendshapes, e.g. DMPLs, from http://smpl.is.tue.mpg.de.\n",
    "In case, you use any of these models in your research please follow their respective citation rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "amass_npz_fname = osp.join(support_dir, 'github_data/dmpl_sample.npz') # the path to body data\n",
    "bdata = np.load(amass_npz_fname)\n",
    "\n",
    "# you can set the gender manually and if it differs from data's then contact or interpenetration issues might happen\n",
    "subject_gender = bdata['gender'].item().decode('utf-8')\n",
    "\n",
    "print('Data keys available:%s'%list(bdata.keys()))\n",
    "\n",
    "print('The subject of the mocap sequence is {}.'.format(subject_gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from human_body_prior.body_model.body_model import BodyModel\n",
    "from human_body_prior.tools.omni_tools import copy2cpu as c2c\n",
    "\n",
    "bm_fname = osp.join(support_dir, 'body_models/smplh/{}/model.npz'.format(subject_gender))\n",
    "dmpl_fname = osp.join(support_dir, 'body_models/dmpls/{}/model.npz'.format(subject_gender))\n",
    "\n",
    "num_betas = 16 # number of body parameters\n",
    "num_dmpls = 8 # number of DMPL parameters\n",
    "\n",
    "bm = BodyModel(bm_fname=bm_fname, num_betas=num_betas, num_dmpls=num_dmpls, dmpl_fname=dmpl_fname).to(comp_device)\n",
    "faces = c2c(bm.f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The provided sample data has the original mocap marker data.\n",
    "In the real AMASS dataset, we include only markers for the test set.\n",
    "For the rest of the subsets you can obtain the marker data from their respective websites.\n",
    "In the following we make PyTorch tensors for parameters controlling different part of the body model.\n",
    "\n",
    "**Note the indices for different body part pose.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "time_length = len(bdata['trans'])\n",
    "\n",
    "body_parms = {\n",
    "    'root_orient': torch.Tensor(bdata['poses'][:, :3]).to(comp_device), # controls the global root orientation\n",
    "    'pose_body': torch.Tensor(bdata['poses'][:, 3:66]).to(comp_device), # controls the body\n",
    "    'pose_hand': torch.Tensor(bdata['poses'][:, 66:]).to(comp_device), # controls the finger articulation\n",
    "    'trans': torch.Tensor(bdata['trans']).to(comp_device), # controls the global body position\n",
    "    'betas': torch.Tensor(np.repeat(bdata['betas'][:num_betas][np.newaxis], repeats=time_length, axis=0)).to(comp_device), # controls the body shape. Body shape is static\n",
    "    'dmpls': torch.Tensor(bdata['dmpls'][:, :num_dmpls]).to(comp_device) # controls soft tissue dynamics\n",
    "}\n",
    "\n",
    "print('Body parameter vector shapes: \\n{}'.format(' \\n'.join(['{}: {}'.format(k,v.shape) for k,v in body_parms.items()])))\n",
    "print('time_length = {}'.format(time_length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Import the required files for viewing out mesh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import trimesh\n",
    "from body_visualizer.tools.vis_tools import colors\n",
    "from body_visualizer.mesh.mesh_viewer import MeshViewer\n",
    "from body_visualizer.mesh.sphere import points_to_spheres\n",
    "from body_visualizer.tools.vis_tools import show_image\n",
    "\n",
    "imw, imh=1600, 1600\n",
    "mv = MeshViewer(width=imw, height=imh, use_offscreen=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualize betas and pose_body\n",
    "Let's see how our body looks like using the pose and body shape parameters.\n",
    "We first produce the body surface in batched mode.\n",
    "\n",
    "Now we can visualize each frame of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "body_pose_beta = bm(**{k:v for k,v in body_parms.items() if k in ['pose_body', 'betas']})\n",
    "\n",
    "def vis_body_pose_beta(fId = 0):\n",
    "    body_mesh = trimesh.Trimesh(vertices=c2c(body_pose_beta.v[fId]), faces=faces, vertex_colors=np.tile(colors['grey'], (6890, 1)))\n",
    "    mv.set_static_meshes([body_mesh])\n",
    "    body_image = mv.render(render_wireframe=False)\n",
    "    show_image(body_image)\n",
    "\n",
    "vis_body_pose_beta(fId=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a male subject sitting and havig the hands open.\n",
    "Let's articulate the fingers as well:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualize pose hands\n",
    "To articulate fingers we use the 66:156 pose vector elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "body_pose_hand = bm(**{k:v for k,v in body_parms.items() if k in ['pose_body', 'betas', 'pose_hand']})\n",
    "\n",
    "def vis_body_pose_hand(fId = 0):\n",
    "    body_mesh = trimesh.Trimesh(vertices=c2c(body_pose_hand.v[fId]), faces=faces, vertex_colors=np.tile(colors['grey'], (6890, 1)))\n",
    "    mv.set_static_meshes([body_mesh])\n",
    "    body_image = mv.render(render_wireframe=False)\n",
    "    show_image(body_image)\n",
    "\n",
    "vis_body_pose_hand(fId=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "It seems that the subject is holding something with one hand.\n",
    "\n",
    "### Visualize body joints\n",
    "\n",
    "To access joint locations of the body one can use **Jtr** attribute of the returned body.\n",
    "These can be visualized as spheres.\n",
    "Here we render the body transparently to visualize the joints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def vis_body_joints(fId = 0):\n",
    "    joints = c2c(body_pose_hand.Jtr[fId])\n",
    "    joints_mesh = points_to_spheres(joints, point_color = colors['red'], radius=0.005)\n",
    "\n",
    "    mv.set_static_meshes([joints_mesh])\n",
    "    body_image = mv.render(render_wireframe=False)\n",
    "    show_image(body_image)\n",
    "\n",
    "vis_body_joints(fId=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualize DMPLs\n",
    "You can control the soft tissue dynamics with DMPL parameters.\n",
    "Please have in mind, to better visualize DMPLs you would need to render a sequence. Please refer to AMASS DMPL notebook for animation renders.\n",
    "Refer to full renders of the parameter sequences in our [website](https://amass.is.tue.mpg.de/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "body_dmpls = bm(**{k:v for k,v in body_parms.items() if k in ['pose_body', 'betas', 'pose_hand', 'dmpls']})\n",
    "\n",
    "def vis_body_dmpls(fId = 0):\n",
    "    body_mesh = trimesh.Trimesh(vertices=c2c(body_dmpls.v[fId]), faces=faces, vertex_colors=np.tile(colors['grey'], (6890, 1)))\n",
    "    mv.set_static_meshes([body_mesh])\n",
    "    body_image = mv.render(render_wireframe=False)\n",
    "    show_image(body_image)\n",
    "\n",
    "vis_body_dmpls(fId=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Visualizing the global root orientation\n",
    "\n",
    "In the above examples we don't use the global translation or rotation.\n",
    "However, we can globally control the character position and orientation with **trans**, and **root_orient** parameters respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "body_trans_root = bm(**{k:v for k,v in body_parms.items() if k in ['pose_body', 'betas', 'pose_hand', 'dmpls',\n",
    "                                                                   'trans', 'root_orient']})\n",
    "\n",
    "def vis_body_trans_root(fId = 0):\n",
    "    body_mesh = trimesh.Trimesh(vertices=c2c(body_trans_root.v[fId]), faces=faces, vertex_colors=np.tile(colors['grey'], (6890, 1)))\n",
    "    mv.set_static_meshes([body_mesh])\n",
    "    body_image = mv.render(render_wireframe=False)\n",
    "    show_image(body_image)\n",
    "\n",
    "vis_body_trans_root(fId=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%% md\n"
    }
   },
   "source": [
    "The global root orientation of amass is so that if you render with MeshViewer you will always get a top view of the body.\n",
    "One can rotate the body into front view by transforming the mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def vis_body_transformed(fId = 0):\n",
    "    body_mesh = trimesh.Trimesh(vertices=c2c(body_trans_root.v[fId]), faces=faces, vertex_colors=np.tile(colors['grey'], (6890, 1)))\n",
    "    body_mesh.apply_transform(trimesh.transformations.rotation_matrix(-90, (0, 0, 1)))\n",
    "    body_mesh.apply_transform(trimesh.transformations.rotation_matrix(30, (1, 0, 0)))\n",
    "\n",
    "    mv.set_static_meshes([body_mesh])\n",
    "    body_image = mv.render(render_wireframe=False)\n",
    "    show_image(body_image)\n",
    "\n",
    "vis_body_transformed(fId=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amass",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
